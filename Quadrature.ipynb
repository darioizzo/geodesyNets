{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Numerical integration methods for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core stuff\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy\n",
    "from copy import deepcopy\n",
    "\n",
    "# pytorch\n",
    "from torch import nn\n",
    "import torch\n",
    "# For debugging and development purposes this is now set to float64 ... change for speed on GPUs\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "# misc\n",
    "import sobol_seq\n",
    "from scipy import integrate\n",
    "from tqdm import tqdm\n",
    "\n",
    "# plotting stuff\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib notebook\n",
    "\n",
    "# We generate a low-discrepancy sequence here and keep it in memory (generating it requires some CPU time)\n",
    "sobol_points_3d = sobol_seq.i4_sobol_generate(3, 1000000)\n",
    "sobol_points_1d = sobol_seq.i4_sobol_generate(1, 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some test functions to verify functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_test(x):\n",
    "    return 1*x[0]+10*x[1]+100*x[2]\n",
    "\n",
    "def f1(x):\n",
    "    return 4 - x**2\n",
    "\n",
    "def f1_2(x):\n",
    "    return x**5 - 4*x**4 + 23*x**3 + 4*x**2 - 3*x + 1\n",
    "\n",
    "def f2(x):\n",
    "    return 4 - x[:,0]**2 - x[:,1]**2 - x[:,2]**2\n",
    "\n",
    "def f3(x):\n",
    "    return 3 * x[:,0] - 5 * x[:,1]**2 + x[:,2]**3\n",
    "\n",
    "def f4(x):\n",
    "    return 10 * x[:,0]**3 - 5 * x[:,1]**4 + 3 * x[:,2]**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Montecarlo\n",
    "def MC(f, dim, N = 1000):\n",
    "    # We generate randomly points in the [-1,1]^d bounds\n",
    "    sample_points = torch.rand(N,dim) * 2 - 1\n",
    "    return 2**dim * torch.sum(f(sample_points)) / N\n",
    "\n",
    "# Low-discrepancy Montecarlo\n",
    "def LDMC(f, dim, N = 1000, noise = 1e-5):\n",
    "    if dim == 1:\n",
    "        sobol_points = sobol_points_1d\n",
    "    else:\n",
    "        sobol_points = sobol_points_3d\n",
    "    # We generate randomly points in the [-1,1]^3 bounds\n",
    "    sample_points = torch.tensor(sobol_points[:N,:] * 2 - 1) + torch.rand(N,dim) * noise\n",
    "    return 2**dim * torch.sum(f(sample_points)) / N\n",
    "\n",
    "# Utilize Scipy NQUAD\n",
    "def NQUAD(f, dim, limit = 50,epsabs=100.0,epsrel=100.0):\n",
    "    if dim==1:\n",
    "        integration_domain = [[-1,1]]\n",
    "        func = lambda x: f(torch.tensor([[x]]))\n",
    "    else:\n",
    "        integration_domain = [[-1,1],[-1,1],[-1,1]]\n",
    "        func = lambda x,y,z: f(torch.tensor([[x,y,z]]))\n",
    "    opts={\"limit\": limit, \"epsabs\" : epsabs, \"epsrel\" : epsrel}\n",
    "    nquad_out = integrate.nquad(func, integration_domain,opts=opts,full_output=True)\n",
    "    retval = torch.tensor([[nquad_out[0]]])[0]\n",
    "    return retval,nquad_out\n",
    "\n",
    "#1D Trapezoid method in torch\n",
    "def trapezoid1D(f,N = 2,integration_domain = [[-1,1]],verbose=False):\n",
    "    #Create grid and assemble evaluation points\n",
    "    grid_1d = torch.linspace(integration_domain[0][0],integration_domain[0][1],N)\n",
    "    h = (grid_1d[1] - grid_1d[0])\n",
    "    eval_points = torch.tensor([x for x in grid_1d])\n",
    "    \n",
    "    #Evaluate all points\n",
    "    evaluations = f(eval_points)\n",
    "    \n",
    "    #Compute f0,f1,f2\n",
    "    f0 = evaluations[0:-1]\n",
    "    f1 = evaluations[1:]\n",
    "    areas = h / 2 * (f0 + f1)\n",
    "    if verbose: print(\"areas=\",areas)\n",
    "    return torch.sum(areas)\n",
    "\n",
    "#1D Composite simpson method in torch\n",
    "def simpson1D(f,N = 3,integration_domain = [[-1,1]],verbose=False):\n",
    "    if N % 2 != 1: raise(ValueError(\"N cannot be even due to necessary subdivisions.\"))\n",
    "    #Create grid and assemble evaluation points\n",
    "    grid_1d = torch.linspace(integration_domain[0][0],integration_domain[0][1],N)\n",
    "    h = (grid_1d[2] - grid_1d[0]) / 2\n",
    "    eval_points = torch.tensor([x for x in grid_1d])\n",
    "    if verbose: print(\"eval_points=\",eval_points)\n",
    "    if verbose: print(\"h=\",h)\n",
    "    \n",
    "    #Evaluate all points\n",
    "    evaluations = f(eval_points)\n",
    "    if verbose: print(\"evaluations=\",evaluations)\n",
    "    \n",
    "    #Compute f0,f1,f2\n",
    "    f0 = evaluations[0:-2][::2]\n",
    "    f1 = evaluations[1:-1][::2]\n",
    "    f2 = evaluations[2:][::2]\n",
    "    if verbose: print(\"f0,f1,f2\",f0,f1,f2)\n",
    "    areas = h / 3 * (f0 + 4 * f1 + f2)\n",
    "    if verbose: print(\"areas=\",areas)\n",
    "    return torch.sum(areas)\n",
    "\n",
    "#3D Trapezoid method in torch\n",
    "def trapezoid3D(f,N = 2,integration_domain = [[-1,1]],verbose=False):\n",
    "    #Create grid and assemble evaluation points\n",
    "    grid_1d = torch.linspace(integration_domain[0][0],integration_domain[0][1],N)\n",
    "    h = (grid_1d[1] - grid_1d[0])\n",
    "    x,y,z = torch.meshgrid(grid_1d,grid_1d,grid_1d)\n",
    "    eval_points = torch.stack((x.flatten(),y.flatten(),z.flatten())).transpose(0,1)\n",
    "    if verbose: print(\"eval_points=\",eval_points)\n",
    "    if verbose: print(\"h=\",h)\n",
    "    \n",
    "    #Evaluate all points\n",
    "    evaluations = f(eval_points).reshape([N,N,N]) #map to z,y,x\n",
    "    if verbose: print(\"evaluations=\",evaluations)\n",
    "    \n",
    "    # area = h / 2 + (f0 + f2)\n",
    "    int_x = h / 2 * (evaluations[:,:,0:-1] + evaluations[:,:,1:])\n",
    "    int_x = torch.sum(int_x,dim=2)\n",
    "    int_y = h / 2 * (int_x[:,0:-1] + int_x[:,1:])\n",
    "    int_y = torch.sum(int_y,dim=1)\n",
    "    int_z = h / 2 * (int_y[0:-1] + int_y[1:])\n",
    "    int_z = torch.sum(int_z,dim=0)\n",
    "    if verbose: print(\"int_x\",int_x.shape,int_x)\n",
    "    if verbose: print(\"int_y\",int_y.shape,int_y)\n",
    "    if verbose: print(\"int_z\",int_z.shape,int_z)\n",
    "    return int_z\n",
    "\n",
    "#1D Composite simpson method in torch\n",
    "def simpson3D(f,N = 3,integration_domain = [[-1,1]],verbose=False):\n",
    "    if N % 2 != 1: raise(ValueError(\"N cannot be even due to necessary subdivisions.\"))\n",
    "    #Create grid and assemble evaluation points\n",
    "    grid_1d = torch.linspace(integration_domain[0][0],integration_domain[0][1],N)\n",
    "    h = (grid_1d[2] - grid_1d[0]) / 2\n",
    "    x,y,z = torch.meshgrid(grid_1d,grid_1d,grid_1d)\n",
    "    eval_points = torch.stack((x.flatten(),y.flatten(),z.flatten())).transpose(0,1)\n",
    "    if verbose: print(\"eval_points=\",eval_points)\n",
    "    if verbose: print(\"h=\",h)\n",
    "    \n",
    "    #Evaluate all points\n",
    "    evaluations = f(eval_points).reshape([N,N,N]) #map to z,y,x\n",
    "    if verbose: print(\"evaluations=\",evaluations.shape,evaluations)\n",
    "    \n",
    "    # area = h / 3 + (f0 + 4*f1 + f2)\n",
    "    int_x = h / 3 * (evaluations[:,:,0:-2][:,:,::2] + 4 * evaluations[:,:,1:-1][:,:,::2] + evaluations[:,:,2:][:,:,::2])\n",
    "    int_x = torch.sum(int_x,dim=2)\n",
    "    int_y = h / 3 * (int_x[:,0:-2][:,::2] + 4 * int_x[:,1:-1][:,::2] + int_x[:,2:][:,::2])\n",
    "    int_y = torch.sum(int_y,dim=1)\n",
    "    int_z = h / 3 * (int_y[0:-2][::2] + 4 * int_y[1:-1][::2] + int_y[2:][::2])\n",
    "    int_z = torch.sum(int_z,dim=0)\n",
    "    if verbose: print(\"int_x\",int_x.shape,int_x)\n",
    "    if verbose: print(\"int_y\",int_y.shape,int_y)\n",
    "    if verbose: print(\"int_z\",int_z.shape,int_z)\n",
    "    return int_z\n",
    "\n",
    "#Wrapper for different dim\n",
    "def simpson(f,dim,N,verbose=False):\n",
    "    if dim==1:\n",
    "        if N % 2 == 0: \n",
    "            N -= 1\n",
    "        return simpson1D(f=f,N=N,verbose=verbose)\n",
    "    if dim==3:\n",
    "        N = int(np.round(np.cbrt(N)))\n",
    "        if N % 2 == 0: \n",
    "            N -= 1\n",
    "        return simpson3D(f=f,N=N,verbose=verbose)\n",
    "    else:\n",
    "        raise(NotImplementedError())\n",
    "\n",
    "#Wrapper for different dim\n",
    "def trapezoid(f,dim,N):\n",
    "    if dim==1:\n",
    "        return trapezoid1D(f=f,N=N)\n",
    "    if dim==3:\n",
    "        N = int(np.round(np.cbrt(N)))\n",
    "        return trapezoid3D(f=f,N=N)\n",
    "    else:\n",
    "        raise(NotImplementedError())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it on the defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f4 #function to test\n",
    "dim = 3 #dim of the function\n",
    "ground_truth, _ = NQUAD(f, dim, epsabs = 0.000000000001,epsrel = 0.000000000001) #ground_truth\n",
    "grid = range(100, 30000, 500) #eval number to test\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = []\n",
    "for g in tqdm(grid):\n",
    "    mc.append(torch.abs(MC(f, dim, N = g).detach() - ground_truth).numpy())\n",
    "\n",
    "ld = []\n",
    "for g in tqdm(grid):\n",
    "    ld.append(torch.abs(LDMC(f, dim, N = g, noise=1e-5).detach() - ground_truth).numpy())\n",
    "\n",
    "    \n",
    "qd,qd_steps = [], []\n",
    "for limit in tqdm(range(1,50,5)):\n",
    "    result, info = NQUAD(f,dim,limit=limit)\n",
    "    qd.append(torch.abs(result.detach() - ground_truth).numpy())\n",
    "    qd_steps.append(info[2][\"neval\"])\n",
    "    \n",
    "simp = []\n",
    "for g in tqdm(grid):\n",
    "    simp.append(torch.abs(simpson(f, dim, N = g).detach() - ground_truth).numpy())\n",
    "    \n",
    "trap = []\n",
    "for g in tqdm(grid):\n",
    "    trap.append(torch.abs(trapezoid(f, dim, N = g).detach() - ground_truth).numpy())\n",
    "    \n",
    "# We plot the results\n",
    "fig = plt.figure()\n",
    "plt.semilogy(grid, mc, label = \"naive MC\")\n",
    "plt.semilogy(grid, ld, label = \"low-discrepancy\")\n",
    "plt.semilogy(qd_steps, qd, label = \"nquad\")\n",
    "plt.semilogy(grid, simp, label = \"simpsons\")\n",
    "plt.semilogy(grid, trap, label = \"trapezoid\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test on real model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the data from MPIA containing pseudo-stable asteroid shapes\n",
    "f = h5py.File('sample_vis_data/sample_01/state_10567.hdf5','r')\n",
    "f2 = h5py.File('sample_vis_data/sample_01/global.hdf5', 'r')\n",
    "# The file state_ ... contains the positions of all particles as well as the indices\n",
    "# of those belonging to a cluster. Here we extract the largest ones.\n",
    "dims = [(len(f[cluster][()]), cluster) for cluster in f.keys() if 'cluster' in cluster]\n",
    "largest_clusters = sorted(dims,reverse=True)\n",
    "# We have ordered the largest asteroids, we now extract positions for one in particular\n",
    "rank = 4\n",
    "print(\"Target: \", largest_clusters[rank][1])\n",
    "# The particles idxs for this cluster\n",
    "idx = f[largest_clusters[rank][1]][()]\n",
    "# The particle radius\n",
    "radius = f2['radius'][()]\n",
    "# Particle positions\n",
    "x_raw = f['x'][()][idx]\n",
    "y_raw = f['y'][()][idx]\n",
    "z_raw = f['z'][()][idx]\n",
    "print(\"Diameter: \", 2 * radius)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# We put xyz in a different shape (point_cloud)\n",
    "point_cloud = np.append(x_raw, np.append(y_raw,z_raw))\n",
    "point_cloud = point_cloud.reshape((3,len(x_raw)))\n",
    "point_cloud = np.transpose(point_cloud)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=4, algorithm='ball_tree').fit(point_cloud)\n",
    "distances, indices = nbrs.kneighbors(point_cloud)\n",
    "\n",
    "print(\"Minimum distance between particles: \", min(distances[:,1]))\n",
    "print(\"Maximum distance between particles: \", max(distances[:,1]))\n",
    "\n",
    "# We take out particles that are not \"touching\" at least two neighbours\n",
    "unstable_points = np.where(distances[:, 3]> 2 * radius * 1.01)[0]\n",
    "print(\"Number of unstable points: \", len(unstable_points))\n",
    "x = np.delete(x_raw, unstable_points, 0)\n",
    "y = np.delete(y_raw, unstable_points, 0)\n",
    "z = np.delete(z_raw, unstable_points, 0)\n",
    "# We subtract the mean so that the origin is the center of figure\n",
    "x = x - np.mean(x)\n",
    "y = y - np.mean(y)\n",
    "z = z - np.mean(z)\n",
    "# We normalize so that the axes are at most one\n",
    "max_value = max([max(abs(it)) for it in [x,y,z]])\n",
    "x = x / max_value\n",
    "y = y / max_value\n",
    "z = z / max_value\n",
    "plot_radius = radius /  max_value  * 3000\n",
    "# We put xyz in a different shape (point_cloud)\n",
    "point_cloud = np.append(x, np.append(y,z))\n",
    "point_cloud = point_cloud.reshape((3,len(x)))\n",
    "point_cloud = np.transpose(point_cloud)\n",
    "point_cloud = torch.tensor(point_cloud)\n",
    "# This will create the labels for the supervised learning\n",
    "def U_L(target_points, point_cloud):\n",
    "    retval=torch.empty(len(target_points),1)\n",
    "    for i, target_point in enumerate(target_points):\n",
    "        retval[i] = torch.mean(1./torch.norm(torch.sub(point_cloud,target_point), dim=1))\n",
    "    return - retval \n",
    "\n",
    "# All encodings work taking as input a tensor (N, 3) containing the cartesian coordinates of N points\n",
    "# and returning a tensor of (N, M) that can be used as input to the ANN\n",
    "\n",
    "# Encoding N.1 (directional encoding):\n",
    "# x = [x,y,z] is encoded as [ix, iy, iz, r]\n",
    "def directional_encoding(sampled_points):\n",
    "    unit = sampled_points / torch.norm(sampled_points,dim=1).view(-1,1)\n",
    "    return torch.cat((unit, torch.norm(sampled_points,dim=1).view(-1,1)), dim=1)\n",
    "\n",
    "# Encoding N.2 (positional encoding):\n",
    "# x = [x,y,z] is encoded as [sin(pi x), sin(pi y), sin(pi z), cos(pi x), cos(pi y), cos(pi z), sin(2 pi x), ....]\n",
    "def positional_encoding(sampled_points, N = 4):\n",
    "    retval = torch.cat((torch.sin(np.pi * dummy[:,0]).view(-1,1), torch.cos(np.pi * dummy[:,0]).view(-1,1), torch.sin(np.pi * dummy[:,1]).view(-1,1), torch.cos(np.pi * dummy[:,1]).view(-1,1), torch.sin(np.pi * dummy[:,2]).view(-1,1), torch.cos(np.pi * dummy[:,2]).view(-1,1)), dim=1)\n",
    "    for i in range(1, N):\n",
    "        retval = torch.cat((retval, torch.sin(2**i * np.pi * dummy[:,0]).view(-1,1), torch.cos(2**i * np.pi * dummy[:,0]).view(-1,1), torch.sin(2**i * np.pi * dummy[:,1]).view(-1,1), torch.cos(2**i * np.pi * dummy[:,1]).view(-1,1), torch.sin(2**i * np.pi * dummy[:,2]).view(-1,1), torch.cos(2**i * np.pi * dummy[:,2]).view(-1,1)), dim=1)\n",
    "    return retval\n",
    "\n",
    "# Encoding N.3 (direct encoding):\n",
    "def direct_encoding(sampled_points):\n",
    "    return sampled_points\n",
    "        \n",
    "# Encoding N.4 (spherical coordinates). These can be used with positional encoding to create effectively harmonics\n",
    "def spherical_coordinates(sampled_points):\n",
    "    phi = torch.atan2(dummy[:,1], dummy[:,0]) / np.pi\n",
    "    r = torch.norm(dummy, dim=1)\n",
    "    theta = torch.div(dummy[:,2], r)\n",
    "    return torch.cat((r.view(-1,1), phi.view(-1,1), theta.view(-1,1)), dim=1)\n",
    "# Encoding choosen\n",
    "encoding = directional_encoding\n",
    "\n",
    "# Network initialization scheme (note that if xavier uniform is used all outputs will start at, roughly 0.5)\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.uniform_(m.bias.data, -0.0, 0.0)\n",
    "\n",
    "# Network architecture. Note that the dimensionality of the first linear layer must match the output\n",
    "# of the encoding chosen\n",
    "n_neurons = 100\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(4,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,n_neurons),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(n_neurons,1),\n",
    "          nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "# Applying our weight initialization\n",
    "_  = model.apply(weights_init)\n",
    "\n",
    "# IF YOU NOW WANT TO LOAD THE ALREADY TRAINED NETWORK UNCOMMENT HERE.\n",
    "## It is important that the network architecture is compatible, otherwise this will fail\n",
    "model.load_state_dict(torch.load(\"models/\" + largest_clusters[rank][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup integration methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a low-discrepancy sequence here and keep it in memory (generating it requires some CPU time)\n",
    "sobol_points = sobol_seq.i4_sobol_generate(3, 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Montecarlo\n",
    "def U_Pmc(target_points, model, N = 3000):\n",
    "    # We generate randomly points in the [-1,1]^3 bounds\n",
    "    sample_points = torch.rand(N,3) * 2 - 1\n",
    "    nn_inputs = encoding(sample_points)\n",
    "    rho = model(nn_inputs)\n",
    "    retval=torch.empty(len(target_points),1)\n",
    "    # Only for the points inside we accumulate the integrand (MC method)\n",
    "    for i, target_point in enumerate(target_points):\n",
    "        retval[i] = torch.sum(rho/torch.norm(target_point - sample_points, dim=1).view(-1,1)) / N\n",
    "    return  - 8 * retval\n",
    "\n",
    "# Low-discrepancy Montecarlo\n",
    "def U_Pld(target_points, model, N = 3000, noise = 1e-5):\n",
    "    # We generate randomly points in the [-1,1]^3 bounds\n",
    "    sample_points = torch.tensor(sobol_points[:N,:] * 2 - 1) + torch.rand(N,3) * noise\n",
    "    nn_inputs = encoding(sample_points)\n",
    "    rho = model(nn_inputs)\n",
    "    retval=torch.empty(len(target_points),1)\n",
    "    # Only for the points inside we accumulate the integrand (MC method)\n",
    "    for i, target_point in enumerate(target_points):\n",
    "        retval[i] = torch.sum(rho/torch.norm(target_point - sample_points, dim=1).view(-1,1)) / N\n",
    "    return  - 8 * retval\n",
    "\n",
    "def f(sample_points,target_point,model):\n",
    "    nn_inputs = encoding(sample_points)\n",
    "    nn_inputs[nn_inputs!=nn_inputs] = 0.0 #set Nans to 0\n",
    "    rho = model(nn_inputs)\n",
    "    value = rho/torch.norm(target_point - sample_points, dim=1).view(-1,1)\n",
    "    return value.detach()\n",
    "\n",
    "def U_quadrature(target_points, model, integration_domain = [[-1,1],[-1,1],[-1,1]], limit = 2,epsabs=100.0,epsrel=100.0):\n",
    "    opts={\"limit\": limit, \"epsabs\" : epsabs, \"epsrel\" : epsrel}\n",
    "    retval = torch.empty(len(target_points),1)\n",
    "    nquad_out = []\n",
    "    for i, target_point in enumerate(target_points):\n",
    "        func = lambda x,y,z: f(torch.tensor([[x,y,z]]),target_point,model)\n",
    "        nquad_out.append(integrate.nquad(func, integration_domain,opts=opts,full_output=True))\n",
    "        retval[i] = -nquad_out[-1][0]\n",
    "    return retval,nquad_out\n",
    "    \n",
    "def U_simp(target_points, model, N,verbose=False):\n",
    "    retval = torch.empty(len(target_points),1)\n",
    "    for i, target_point in enumerate(target_points):\n",
    "        func = lambda x: f(x,target_point,model)\n",
    "        retval[i] = simpson(func,dim=3,N=N,verbose=verbose)\n",
    "    return -retval\n",
    "\n",
    "def U_trap(target_points, model, N,verbose=False):\n",
    "    if N % 2 == 0: \n",
    "        N -= 1\n",
    "    retval = torch.empty(len(target_points),1)\n",
    "    for i, target_point in enumerate(target_points):\n",
    "        func = lambda x: f(x,target_point,model)\n",
    "        retval[i] = trapezoid(func,dim=3,N=N)\n",
    "    return -retval\n",
    "\n",
    "def U_trap_opt(target_points, model, N,verbose=False):\n",
    "    N = int(np.round(np.cbrt(N))) #approximate subdivisions\n",
    "    retval = torch.empty(len(target_points),1) #init result vector\n",
    "    \n",
    "    #Create grid and assemble evaluation points\n",
    "    grid_1d = torch.linspace(-1,1,N)\n",
    "    h = (grid_1d[1] - grid_1d[0])\n",
    "    x,y,z = torch.meshgrid(grid_1d,grid_1d,grid_1d)\n",
    "    eval_points = torch.stack((x.flatten(),y.flatten(),z.flatten())).transpose(0,1)\n",
    "    if verbose: print(\"eval_points=\",eval_points)\n",
    "    if verbose: print(\"h=\",h)\n",
    "    \n",
    "    #Evaluate Rho on the grid\n",
    "    nn_inputs = encoding(eval_points) #Encode grid\n",
    "    nn_inputs[nn_inputs!=nn_inputs] = 0.0 #set Nans to 0\n",
    "    rho = model(nn_inputs)\n",
    "    \n",
    "    for i, target_point in enumerate(target_points):\n",
    "        \n",
    "        f_values = rho/torch.norm(target_point - eval_points, dim=1).view(-1,1).detach()\n",
    "\n",
    "        #Evaluate all points\n",
    "        evaluations = f_values.reshape([N,N,N]) #map to z,y,x\n",
    "        if verbose: print(\"evaluations=\",evaluations)\n",
    "\n",
    "        # area = h / 2 + (f0 + f2)\n",
    "        int_x = h / 2 * (evaluations[:,:,0:-1] + evaluations[:,:,1:])\n",
    "        int_x = torch.sum(int_x,dim=2)\n",
    "        int_y = h / 2 * (int_x[:,0:-1] + int_x[:,1:])\n",
    "        int_y = torch.sum(int_y,dim=1)\n",
    "        int_z = h / 2 * (int_y[0:-1] + int_y[1:])\n",
    "        int_z = torch.sum(int_z,dim=0)\n",
    "        if verbose: print(\"int_x\",int_x.shape,int_x)\n",
    "        if verbose: print(\"int_y\",int_y.shape,int_y)\n",
    "        if verbose: print(\"int_z\",int_z.shape,int_z)\n",
    "    \n",
    "        retval[i] = int_z\n",
    "    return -retval.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_trap(target_points, model, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_trap_opt(target_points, model, N=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we create some target points where to compute the potential\n",
    "torch.manual_seed(42)\n",
    "N_try = 10\n",
    "target_points = (torch.rand(N_try,3)*2-1)*1.1\n",
    "a = torch.logical_and((target_points[:,0]>-1),(target_points[:,0]<1))\n",
    "b = torch.logical_and((target_points[:,1]>-1),(target_points[:,1]<1))\n",
    "c = torch.logical_and((target_points[:,2]>-1),(target_points[:,2]<1))\n",
    "d = torch.logical_and(torch.logical_or(a,b), c)\n",
    "target_points=target_points[d]\n",
    "print(\"Target point is: \", target_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For seed 42 \n",
    "# ground_truth = torch.tensor([[-0.6497132186723324],[-1.0661419291444170],[-0.5982705907123077],[-1.0310878380126529],[-0.9525779194515801],[-0.8621937637431156],[-0.8976110804434343],[-1.1594308542434955],[-0.8590986260083082]])\n",
    "# ground_truth, _ = U_quadrature(target_points, model, epsabs = 0.000001,epsrel = 0.000001)\n",
    "ground_truth = U_trap_opt(target_points, model, N=1000000)\n",
    "\n",
    "torch.set_printoptions(precision=16)\n",
    "print(\"Ground truth is: \", ground_truth)\n",
    "torch.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile runtime performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit U_Pmc(target_points, model, N = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit U_Pld(target_points, model, N = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit U_trap(target_points, model, N = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit U_trap_opt(target_points, model, N = N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile accuracy vs evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = range(1000, 500000, 25000)\n",
    "mc,ld,simp,trap = [],[],[],[]\n",
    "for g in tqdm(grid):\n",
    "    mc.append(torch.abs(U_Pmc(target_points, model, N = g).detach() - ground_truth).numpy())\n",
    "    ld.append(torch.abs(U_Pld(target_points, model, N = g, noise=1e-5).detach() - ground_truth).numpy())\n",
    "#     simp.append(torch.abs(U_simp(target_points, model, N = g).detach() - ground_truth).numpy())\n",
    "    trap.append(torch.abs(U_trap_opt(target_points, model, N = g).detach() - ground_truth).numpy())\n",
    "if target_points.shape[0] > 1:\n",
    "    mc = np.mean(mc,axis=1)\n",
    "    ld = np.mean(ld,axis=1)\n",
    "#     simp = np.mean(simp,axis=1)\n",
    "    trap = np.mean(trap,axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We plot the results\n",
    "fig = plt.figure()\n",
    "plt.semilogy(grid, mc, label = \"naive MC\")\n",
    "plt.semilogy(grid, ld, label = \"low-discrepancy\")\n",
    "plt.semilogy(grid, trap, label = \"trapezoid quadrature\")\n",
    "# plt.semilogy(grid, simp, label = \"composite s-impson quadrature\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create some target points where to compute the potential\n",
    "torch.manual_seed(42)\n",
    "N_try = 1\n",
    "target_points = (torch.rand(N_try,3)*2-1)*1.1\n",
    "a = torch.logical_and((target_points[:,0]>-1),(target_points[:,0]<1))\n",
    "b = torch.logical_and((target_points[:,1]>-1),(target_points[:,1]<1))\n",
    "c = torch.logical_and((target_points[:,2]>-1),(target_points[:,2]<1))\n",
    "d = torch.logical_and(torch.logical_or(a,b), c)\n",
    "target_points=target_points[d]\n",
    "print(\"Target point is: \", target_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow, run only to generate again the plot below\n",
    "grid = range(1000, 250000, 25000)\n",
    "mc_val,ld_val,simp_val,trap_val = [],[],[],[]\n",
    "for g in tqdm(grid):\n",
    "#     mc_val.append(torch.abs(U_Pmc(target_points, model, N = g).detach()).numpy().squeeze())\n",
    "    ld_val.append(torch.abs(U_Pld(target_points, model, N = g, noise=1e-5).detach()).numpy().squeeze())\n",
    "    simp_val.append(torch.abs(U_simp(target_points, model, N = g).detach()).numpy().squeeze())\n",
    "    trap_val.append(torch.abs(U_trap_opt(target_points, model, N = g).detach()).numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the results\n",
    "fig = plt.figure()\n",
    "# plt.semilogy(grid, mc_val, label = \"naive MC\")\n",
    "plt.semilogy(grid, ld_val, label = \"low-discrepancy\")\n",
    "# plt.semilogy(qd_steps, qd, label = \"nquad\")\n",
    "plt.semilogy(grid, trap_val, label = \"trapezoid quadrature\")\n",
    "plt.semilogy(grid, simp_val, label = \"composite simpson quadrature\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the results\n",
    "fig = plt.figure()\n",
    "# plt.semilogy(grid, mc_val, label = \"naive MC\")\n",
    "plt.semilogy(grid, np.abs(ld_val-ld_val[-1]), label = \"low-discrepancy\")\n",
    "# plt.semilogy(qd_steps, qd, label = \"nquad\")\n",
    "plt.semilogy(grid, np.abs(trap_val-trap_val[-1]), label = \"trapezoid quadrature\")\n",
    "plt.semilogy(grid, np.abs(simp_val-simp_val[-1]), label = \"composite simpson quadrature\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
